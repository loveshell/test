<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<configuration>
	<property>
		<name>mapreduce.shuffle.provider.plugin.classes</name>
		<value>org.apache.hadoop.mapred.TaskTracker$DefaultShuffleProvider</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>mapred.job.restart.recover</name>
		<value>true</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>job.end.retry.interval</name>
		<value>30000</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hbase.master.ipc.address</name>
		<value>0.0.0.0</value>
		<source>hbase-site.xml</source>
	</property>
	<property>
		<name>mapred.job.tracker.retiredjobs.cache.size</name>
		<value>1000</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>mapreduce.jobhistory.cleaner.interval-ms</name>
		<value>86400000</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hbase.regions.slop</name>
		<value>0.2</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>dfs.image.transfer.bandwidthPerSec</name>
		<value>0</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>mapred.task.profile.reduces</name>
		<value>0-2</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hbase.zookeeper.leaderport</name>
		<value>3888</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>mapreduce.jobtracker.staging.root.dir</name>
		<value>${hadoop.tmp.dir}/mapred/staging</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hbase.regionserver.info.port</name>
		<value>60030</value>
		<source>hbase-site.xml</source>
	</property>
	<property>
		<name>mapred.job.reuse.jvm.num.tasks</name>
		<value>1</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>dfs.block.access.token.lifetime</name>
		<value>600</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>fs.AbstractFileSystem.file.impl</name>
		<value>org.apache.hadoop.fs.local.LocalFs</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>mapred.reduce.tasks.speculative.execution</name>
		<value>true</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hbase.rs.cacheblocksonwrite</name>
		<value>false</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>dfs.domain.socket.path</name>
		<value>/var/run/hadoop-hdfs/dn._PORT</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>hadoop.ssl.keystores.factory.class</name>
		<value>org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>hadoop.http.authentication.kerberos.keytab</name>
		<value>${user.home}/hadoop.keytab</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>io.seqfile.sorter.recordlimit</name>
		<value>1000000</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>hbase.data.umask.enable</name>
		<value>false</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>s3.blocksize</name>
		<value>67108864</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>hbase.master.dns.nameserver</name>
		<value>default</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.num.checkpoints.retained</name>
		<value>2</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>hadoop.relaxed.worker.version.check</name>
		<value>true</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>mapred.task.tracker.http.address</name>
		<value>0.0.0.0:50060</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hbase.lease.recovery.dfs.timeout</name>
		<value>610000</value>
		<source>hbase-site.xml</source>
	</property>
	<property>
		<name>dfs.namenode.delegation.token.renew-interval</name>
		<value>86400000</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>io.map.index.interval</name>
		<value>128</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>hfile.format.version</name>
		<value>2</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>s3.client-write-packet-size</name>
		<value>65536</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>hbase.auth.token.max.lifetime</name>
		<value>604800000</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.http-address</name>
		<value>0.0.0.0:50070</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>ha.zookeeper.session-timeout.ms</name>
		<value>5000</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>mapred.system.dir</name>
		<value>${hadoop.tmp.dir}/mapred/system</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hadoop.hdfs.configuration.version</name>
		<value>1</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>s3.replication</name>
		<value>3</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>dfs.datanode.balance.bandwidthPerSec</name>
		<value>1048576</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>mapred.task.tracker.report.address</name>
		<value>127.0.0.1:0</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>mapreduce.reduce.shuffle.connect.timeout</name>
		<value>180000</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>dfs.journalnode.rpc-address</name>
		<value>0.0.0.0:8485</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>hadoop.ssl.enabled</name>
		<value>false</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>hbase.lease.recovery.timeout</name>
		<value>900000</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>dfs.datanode.readahead.bytes</name>
		<value>4193404</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>hadoop.security.groups.cache.warn.after.ms</name>
		<value>5000</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>ipc.client.connect.max.retries.on.timeouts</name>
		<value>45</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>hbase.hregion.memstore.flush.size</name>
		<value>134217728</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>mapred.healthChecker.interval</name>
		<value>60000</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>mapreduce.job.complete.cancel.delegation.tokens</name>
		<value>true</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>dfs.client.failover.max.attempts</name>
		<value>15</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.checkpoint.dir</name>
		<value>file://${hadoop.tmp.dir}/dfs/namesecondary</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>hbase.regionserver.logroll.period</name>
		<value>3600000</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.replication.work.multiplier.per.iteration</name>
		<value>2</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>fs.trash.interval</name>
		<value>1</value>
		<source>core-site.xml</source>
	</property>
	<property>
		<name>ha.health-monitor.check-interval.ms</name>
		<value>1000</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>hadoop.jetty.logs.serve.aliases</name>
		<value>true</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>mapred.skip.map.auto.incr.proc.count</name>
		<value>true</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hadoop.http.authentication.kerberos.principal</name>
		<value>HTTP/_HOST@LOCALHOST</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>mapreduce.job.reduce.shuffle.consumer.plugin.class</name>
		<value>org.apache.hadoop.mapred.ReduceTask$ReduceCopier</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hbase.dynamic.jars.dir</name>
		<value>${hbase.rootdir}/.lib</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>s3native.blocksize</name>
		<value>67108864</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>mapred.child.tmp</name>
		<value>./tmp</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hbase.regionserver.dns.interface</name>
		<value>default</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>mapred.tasktracker.taskmemorymanager.monitoring-interval</name>
		<value>5000</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.edits.dir</name>
		<value>${dfs.namenode.name.dir}</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>ha.health-monitor.sleep-after-disconnect.ms</name>
		<value>1000</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>dfs.encrypt.data.transfer</name>
		<value>false</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>dfs.datanode.http.address</name>
		<value>0.0.0.0:50075</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>hbase.hstore.blockingStoreFiles</name>
		<value>7</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>io.sort.spill.percent</name>
		<value>0.80</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hbase.rpc.engine</name>
		<value>org.apache.hadoop.hbase.ipc.WritableRpcEngine</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.write.stale.datanode.ratio</name>
		<value>0.5f</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>dfs.client.use.datanode.hostname</name>
		<value>false</value>
		<source>hdfs-site.xml</source>
	</property>
	<property>
		<name>mapred.job.shuffle.input.buffer.percent</name>
		<value>0.70</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hadoop.skip.worker.version.check</name>
		<value>false</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hbase.table.archive.directory</name>
		<value>.archive</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>hbase.client.write.buffer</name>
		<value>2097152</value>
		<source>hbase-site.xml</source>
	</property>
	<property>
		<name>hadoop.security.instrumentation.requires.admin</name>
		<value>false</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>mapred.skip.map.max.skip.records</name>
		<value>0</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>mapreduce.reduce.shuffle.maxfetchfailures</name>
		<value>10</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hadoop.security.authorization</name>
		<value>false</value>
		<source>core-site.xml</source>
	</property>
	<property>
		<name>dfs.namenode.fs-limits.min-block-size</name>
		<value>1048576</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>dfs.client.failover.connection.retries.on.timeouts</name>
		<value>0</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.edit.log.autoroll.check.interval.ms</name>
		<value>300000</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>hadoop.security.group.mapping.ldap.search.filter.group</name>
		<value>(objectClass=group)</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.safemode.extension</name>
		<value>30000</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>hbase.zookeeper.property.clientPort</name>
		<value>2181</value>
		<source>hbase-site.xml</source>
	</property>
	<property>
		<name>hbase.regionserver.info.port.auto</name>
		<value>false</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>mapred.task.profile.maps</name>
		<value>0-2</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>dfs.datanode.sync.behind.writes</name>
		<value>false</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>dfs.https.server.keystore.resource</name>
		<value>ssl-server.xml</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>mapred.local.dir</name>
		<value>${hadoop.tmp.dir}/mapred/local</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hadoop.security.group.mapping.ldap.search.attr.group.name</name>
		<value>cn</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>mapred.merge.recordsBeforeProgress</name>
		<value>10000</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>mapred.job.tracker.http.address</name>
		<value>0.0.0.0:50030</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.replication.min</name>
		<value>1</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>hbase.master.logcleaner.ttl</name>
		<value>60000</value>
		<source>hbase-site.xml</source>
	</property>
	<property>
		<name>mapred.compress.map.output</name>
		<value>false</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>mapred.userlog.retain.hours</name>
		<value>24</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hbase.regionserver.optionallogflushinterval</name>
		<value>1000</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>s3native.bytes-per-checksum</name>
		<value>512</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>tfile.fs.output.buffer.size</name>
		<value>262144</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>mapred.tasktracker.reduce.tasks.maximum</name>
		<value>2</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>fs.AbstractFileSystem.hdfs.impl</name>
		<value>org.apache.hadoop.fs.Hdfs</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>mapreduce.job.map.output.collector.class</name>
		<value>org.apache.hadoop.mapred.MapTask$MapOutputBuffer</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.safemode.min.datanodes</name>
		<value>0</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>hbase.rootdir</name>
		<value>hdfs://nameservice1/hbase</value>
		<source>hbase-site.xml</source>
	</property>
	<property>
		<name>hadoop.security.uid.cache.secs</name>
		<value>14400</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>dfs.client.write.exclude.nodes.cache.expiry.interval.millis</name>
		<value>600000</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>mapred.disk.healthChecker.interval</name>
		<value>60000</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>dfs.client.https.need-auth</name>
		<value>false</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>dfs.client.https.keystore.resource</name>
		<value>ssl-client.xml</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.max.objects</name>
		<value>0</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>mapred.cluster.map.memory.mb</name>
		<value>-1</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hbase.zookeeper.dns.interface</name>
		<value>default</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>hadoop.ssl.client.conf</name>
		<value>ssl-client.xml</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>zookeeper.session.timeout</name>
		<value>600000</value>
		<source>hbase-site.xml</source>
	</property>
	<property>
		<name>dfs.namenode.safemode.threshold-pct</name>
		<value>0.999f</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>dfs.webhdfs.user.provider.user.pattern</name>
		<value>^[A-Za-z_][A-Za-z0-9._-]*[$]?$</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>hbase.hstore.compaction.max</name>
		<value>10</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>mapred.task.id</name>
		<value>hb_m_njhadoopmaster2.wind.com.cn,60000,1410429842510</value>
		<source>programatically</source>
	</property>
	<property>
		<name>dfs.blocksize</name>
		<value>134217728</value>
		<source>hdfs-site.xml</source>
	</property>
	<property>
		<name>dfs.namenode.rpc-address.nameservice1.namenode143</name>
		<value>njhadoopmaster1.wind.com.cn:8020</value>
		<source>hdfs-site.xml</source>
	</property>
	<property>
		<name>hbase.security.authorization</name>
		<value>false</value>
		<source>hbase-site.xml</source>
	</property>
	<property>
		<name>mapreduce.tasktracker.outofband.heartbeat</name>
		<value>false</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hbase.master.info.bindAddress</name>
		<value>0.0.0.0</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>fs.s3n.multipart.uploads.enabled</name>
		<value>false</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>io.native.lib.available</name>
		<value>true</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>dfs.client-write-packet-size</name>
		<value>65536</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>mapred.jobtracker.restart.recover</name>
		<value>false</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>mapred.reduce.child.log.level</name>
		<value>INFO</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>mapreduce.shuffle.ssl.address</name>
		<value>0.0.0.0</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hbase.hstore.compactionThreshold</name>
		<value>3</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.http-address.nameservice1.namenode143</name>
		<value>njhadoopmaster1.wind.com.cn:50070</value>
		<source>hdfs-site.xml</source>
	</property>
	<property>
		<name>dfs.namenode.name.dir</name>
		<value>file://${hadoop.tmp.dir}/dfs/name</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>dfs.ha.log-roll.period</name>
		<value>120</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>io.storefile.bloom.block.size</name>
		<value>131072</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>dfs.client.failover.sleep.base.millis</name>
		<value>500</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>dfs.datanode.directoryscan.threads</name>
		<value>1</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>hbase.offheapcache.percentage</name>
		<value>0</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>hbase.regionserver.nbreservationblocks</name>
		<value>4</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>dfs.permissions.enabled</name>
		<value>true</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>hbase.thrift.maxQueuedRequests</name>
		<value>1000</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>dfs.support.append</name>
		<value>true</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>hbase.thrift.minWorkerThreads</name>
		<value>16</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>mapred.inmem.merge.threshold</name>
		<value>1000</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>ipc.client.connection.maxidletime</name>
		<value>10000</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>mapreduce.shuffle.ssl.enabled</name>
		<value>${hadoop.ssl.enabled}</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hbase.data.umask</name>
		<value>000</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.invalidate.work.pct.per.iteration</name>
		<value>0.32f</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>dfs.blockreport.intervalMsec</name>
		<value>21600000</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>fs.s3.sleepTimeSeconds</name>
		<value>10</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.replication.considerLoad</name>
		<value>true</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>dfs.client.block.write.retries</name>
		<value>3</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>hadoop.ssl.server.conf</name>
		<value>ssl-server.xml</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>hbase.balancer.period</name>
		<value>300000</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.name.dir.restore</name>
		<value>false</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>fs.s3n.multipart.uploads.block.size</name>
		<value>67108864</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>dfs.datanode.hdfs-blocks-metadata.enabled</name>
		<value>true</value>
		<source>hdfs-site.xml</source>
	</property>
	<property>
		<name>mapred.reduce.tasks</name>
		<value>1</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>ha.zookeeper.parent-znode</name>
		<value>/hadoop-ha</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>mapred.queue.names</name>
		<value>default</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>io.seqfile.lazydecompress</name>
		<value>true</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>hbase.zookeeper.property.maxClientCnxns</name>
		<value>300</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>dfs.https.enable</name>
		<value>false</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>fail.fast.expired.active.master</name>
		<value>false</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>dfs.replication</name>
		<value>2</value>
		<source>hdfs-site.xml</source>
	</property>
	<property>
		<name>hbase.client.scanner.caching</name>
		<value>1</value>
		<source>hbase-site.xml</source>
	</property>
	<property>
		<name>ipc.client.tcpnodelay</name>
		<value>false</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.https-address.nameservice1.namenode37</name>
		<value>njhadoopmaster2.wind.com.cn:50470</value>
		<source>hdfs-site.xml</source>
	</property>
	<property>
		<name>dfs.namenode.accesstime.precision</name>
		<value>3600000</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>dfs.ha.namenodes.nameservice1</name>
		<value>namenode143,namenode37</value>
		<source>hdfs-site.xml</source>
	</property>
	<property>
		<name>mapred.acls.enabled</name>
		<value>false</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>s3.stream-buffer-size</name>
		<value>4096</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>mapred.tasktracker.dns.nameserver</name>
		<value>default</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>mapred.submit.replication</name>
		<value>10</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hbase.client.retries.number</name>
		<value>100</value>
		<source>programatically</source>
	</property>
	<property>
		<name>dfs.namenode.rpc-address.nameservice1.namenode37</name>
		<value>njhadoopmaster2.wind.com.cn:8020</value>
		<source>hdfs-site.xml</source>
	</property>
	<property>
		<name>hbase.zookeeper.useMulti</name>
		<value>true</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>hbase.zookeeper.dns.nameserver</name>
		<value>default</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>io.file.buffer.size</name>
		<value>4096</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>hfile.index.block.max.size</name>
		<value>131072</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>hbase.regionserver.hlog.reader.impl</name>
		<value>org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogReader</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.audit.loggers</name>
		<value>default</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>mapred.map.tasks.speculative.execution</name>
		<value>true</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.checkpoint.txns</name>
		<value>1000000</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>hbase.zookeeper.property.dataDir</name>
		<value>${hbase.tmp.dir}/zookeeper</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>hbase.hregion.memstore.mslab.enabled</name>
		<value>true</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>hbase.regionserver.dns.nameserver</name>
		<value>default</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.http-address.nameservice1.namenode37</name>
		<value>njhadoopmaster2.wind.com.cn:50070</value>
		<source>hdfs-site.xml</source>
	</property>
	<property>
		<name>mapred.map.child.log.level</name>
		<value>INFO</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hfile.block.index.cacheonwrite</name>
		<value>false</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>kfs.replication</name>
		<value>3</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>mapred.map.max.attempts</name>
		<value>4</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hfile.block.cache.size</name>
		<value>0.0</value>
		<source>programatically</source>
	</property>
	<property>
		<name>dfs.ha.tail-edits.period</name>
		<value>60</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>kfs.stream-buffer-size</name>
		<value>4096</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>mapred.job.shuffle.merge.percent</name>
		<value>0.66</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hbase.regionserver.class</name>
		<value>org.apache.hadoop.hbase.ipc.HRegionInterface</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>hadoop.security.authentication</name>
		<value>simple</value>
		<source>core-site.xml</source>
	</property>
	<property>
		<name>fs.s3.buffer.dir</name>
		<value>${hadoop.tmp.dir}/s3</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>mapred.skip.reduce.auto.incr.proc.count</name>
		<value>true</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hbase.master.info.port</name>
		<value>60010</value>
		<source>hbase-site.xml</source>
	</property>
	<property>
		<name>mapred.job.tracker.jobhistory.lru.cache.size</name>
		<value>5</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.avoid.read.stale.datanode</name>
		<value>true</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>dfs.client.file-block-storage-locations.timeout</name>
		<value>60</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>hbase.rest.threads.min</name>
		<value>2</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>dfs.datanode.drop.cache.behind.writes</name>
		<value>false</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>tfile.fs.input.buffer.size</name>
		<value>262144</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>dfs.block.access.token.enable</name>
		<value>false</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>dfs.journalnode.http-address</name>
		<value>0.0.0.0:8480</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>mapreduce.job.acl-view-job</name>
		<value>
		</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>mapred.job.queue.name</name>
		<value>default</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>ftp.blocksize</name>
		<value>67108864</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>hbase.local.dir</name>
		<value>${hbase.tmp.dir}/local/</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>dfs.datanode.data.dir</name>
		<value>file://${hadoop.tmp.dir}/dfs/data</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>hadoop.policy.file</name>
		<value>hbase-policy.xml</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>ha.failover-controller.cli-check.rpc-timeout.ms</name>
		<value>20000</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>mapred.job.tracker.persist.jobstatus.hours</name>
		<value>0</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.max.extra.edits.segments.retained</name>
		<value>10000</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>mapreduce.job.token.tracking.ids.enabled</name>
		<value>false</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.replication.interval</name>
		<value>3</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>mapreduce.tasktracker.cache.local.numberdirectories</name>
		<value>10000</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hbase.hash.type</name>
		<value>murmur</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>hbase.regionserver.region.split.policy</name>
		<value>org.apache.hadoop.hbase.regionserver.IncreasingToUpperBoundRegionSplitPolicy
		</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.https-address</name>
		<value>0.0.0.0:50470</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>dfs.ha.automatic-failover.enabled</name>
		<value>false</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>ipc.client.kill.max</name>
		<value>10</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>mapred.healthChecker.script.timeout</name>
		<value>600000</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>dfs.image.transfer.timeout</name>
		<value>600000</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>mapred.tasktracker.map.tasks.maximum</name>
		<value>2</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>zookeeper.znode.acl.parent</name>
		<value>acl</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>dfs.client.failover.sleep.max.millis</name>
		<value>15000</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>jobclient.completion.poll.interval</name>
		<value>5000</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>mapred.job.tracker.persist.jobstatus.dir</name>
		<value>/jobtracker/jobsInfo</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>mapreduce.jobhistory.max-age-ms</name>
		<value>2592000000</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>mapreduce.shuffle.ssl.port</name>
		<value>50443</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>dfs.default.chunk.view.size</name>
		<value>32768</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>hbase.auth.key.update.interval</name>
		<value>86400000</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>kfs.bytes-per-checksum</name>
		<value>512</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>mapred.reduce.slowstart.completed.maps</name>
		<value>0.05</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hadoop.http.filter.initializers</name>
		<value>org.apache.hadoop.http.lib.StaticUserWebFilter</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>dfs.datanode.failed.volumes.tolerated</name>
		<value>0</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>io.sort.mb</name>
		<value>100</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hbase.regionserver.regionSplitLimit</name>
		<value>2147483647</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>hadoop.http.authentication.type</name>
		<value>simple</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>hbase.rest.port</name>
		<value>8080</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>dfs.datanode.data.dir.perm</name>
		<value>700</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>ipc.server.listen.queue.size</name>
		<value>128</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>file.stream-buffer-size</name>
		<value>4096</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.fs-limits.max-directory-items</name>
		<value>0</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>io.mapfile.bloom.size</name>
		<value>1048576</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>mapred.combine.recordsBeforeProgress</name>
		<value>10000</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>ftp.replication</name>
		<value>3</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>dfs.datanode.dns.nameserver</name>
		<value>default</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>hbase.client.pause</name>
		<value>1000</value>
		<source>hbase-site.xml</source>
	</property>
	<property>
		<name>mapred.child.java.opts</name>
		<value>-Xmx200m</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>dfs.replication.max</name>
		<value>512</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>mapred.queue.default.state</name>
		<value>RUNNING</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>map.sort.class</name>
		<value>org.apache.hadoop.util.QuickSort</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>dfs.stream-buffer-size</name>
		<value>4096</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.backup.address</name>
		<value>0.0.0.0:50100</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>mapred.jobtracker.instrumentation</name>
		<value>org.apache.hadoop.mapred.JobTrackerMetricsInst</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hadoop.util.hash.type</name>
		<value>murmur</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>dfs.block.access.key.update.interval</name>
		<value>600</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>dfs.datanode.use.datanode.hostname</name>
		<value>false</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>dfs.datanode.dns.interface</name>
		<value>default</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.backup.http-address</name>
		<value>0.0.0.0:50105</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>mapred.output.compression.type</name>
		<value>RECORD</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>mapred.skip.attempts.to.start.skipping</name>
		<value>2</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hbase.rpc.timeout</name>
		<value>600000</value>
		<source>hbase-site.xml</source>
	</property>
	<property>
		<name>kfs.client-write-packet-size</name>
		<value>65536</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>ha.zookeeper.acl</name>
		<value>world:anyone:rwcda</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>io.map.index.skip</name>
		<value>0</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.edit.log.autoroll.multiplier.threshold</name>
		<value>2.0</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>net.topology.node.switch.mapping.impl</name>
		<value>org.apache.hadoop.net.ScriptBasedMapping</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>mapred.cluster.max.map.memory.mb</name>
		<value>-1</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>fs.s3.maxRetries</name>
		<value>4</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.logging.level</name>
		<value>info</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>ha.failover-controller.new-active.rpc-timeout.ms</name>
		<value>60000</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>dfs.client.failover.proxy.provider.nameservice1</name>
		<value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider
		</value>
		<source>hdfs-site.xml</source>
	</property>
	<property>
		<name>s3native.client-write-packet-size</name>
		<value>65536</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>mapred.task.tracker.task-controller</name>
		<value>org.apache.hadoop.mapred.DefaultTaskController</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>mapred.userlog.limit.kb</name>
		<value>0</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hadoop.http.staticuser.user</name>
		<value>dr.who</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>mapreduce.ifile.readahead.bytes</name>
		<value>4194304</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hbase.ipc.client.fallback-to-simple-auth-allowed</name>
		<value>false</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>hadoop.http.authentication.simple.anonymous.allowed</name>
		<value>true</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>hadoop.fuse.timer.period</name>
		<value>5</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.num.extra.edits.retained</name>
		<value>1000000</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>hadoop.rpc.socket.factory.class.default</name>
		<value>org.apache.hadoop.net.StandardSocketFactory</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>hbase.hstore.blockingWaitTime</name>
		<value>90000</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>mapreduce.jobclient.rpc.timeout</name>
		<value>-1</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.handler.count</name>
		<value>10</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>fs.automatic.close</name>
		<value>true</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>dfs.datanode.directoryscan.interval</name>
		<value>21600</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>mapred.map.tasks</name>
		<value>2</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>mapred.local.dir.minspacekill</name>
		<value>0</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hbase.coprocessor.abortonerror</name>
		<value>false</value>
		<source>hbase-site.xml</source>
	</property>
	<property>
		<name>mapred.job.map.memory.mb</name>
		<value>-1</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>mapred.jobtracker.completeuserjobs.maximum</name>
		<value>100</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>mapreduce.jobtracker.split.metainfo.maxsize</name>
		<value>10000000</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hbase.zookeeper.quorum</name>
		<value>njhadoopslave3.wind.com.cn,njhadoopslave5.wind.com.cn,njhadoopslave4.wind.com.cn,njhadoopslave2.wind.com.cn,njhadoopslave1.wind.com.cn
		</value>
		<source>hbase-site.xml</source>
	</property>
	<property>
		<name>io.storefile.bloom.cacheonwrite</name>
		<value>false</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>dfs.client.file-block-storage-locations.num-threads</name>
		<value>10</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>hbase.defaults.for.version</name>
		<value>0.94.15-cdh4.7.0</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>hbase.hregion.max.filesize</name>
		<value>10737418240</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>hadoop.security.group.mapping.ldap.directory.search.timeout</name>
		<value>10000</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>jobclient.progress.monitor.poll.interval</name>
		<value>1000</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hbase.regionserver.logroll.errors.tolerated</name>
		<value>2</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>hbase.master.handler.count</name>
		<value>50</value>
		<source>hbase-site.xml</source>
	</property>
	<property>
		<name>dfs.client.socket-timeout</name>
		<value>600000</value>
		<source>hdfs-site.xml</source>
	</property>
	<property>
		<name>dfs.bytes-per-checksum</name>
		<value>512</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.checkpoint.max-retries</name>
		<value>3</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>zookeeper.znode.parent</name>
		<value>/hbase</value>
		<source>hbase-site.xml</source>
	</property>
	<property>
		<name>dfs.namenode.avoid.write.stale.datanode</name>
		<value>true</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>ftp.stream-buffer-size</name>
		<value>4096</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>ha.health-monitor.rpc-timeout.ms</name>
		<value>45000</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>hadoop.security.group.mapping.ldap.search.attr.member</name>
		<value>member</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>dfs.blockreport.initialDelay</name>
		<value>0</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>mapred.min.split.size</name>
		<value>0</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hadoop.http.authentication.token.validity</name>
		<value>36000</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.delegation.token.max-lifetime</name>
		<value>604800000</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>mapred.output.compression.codec</name>
		<value>org.apache.hadoop.io.compress.DefaultCodec</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hbase.metrics.showTableName</name>
		<value>true</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>mapred.cluster.max.reduce.memory.mb</name>
		<value>-1</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>mapred.cluster.reduce.memory.mb</name>
		<value>-1</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hbase.regionserver.hlog.writer.impl</name>
		<value>org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>s3native.replication</name>
		<value>3</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>mapred.task.profile</name>
		<value>false</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>mapred.reduce.parallel.copies</name>
		<value>5</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hbase.zookeeper.property.syncLimit</name>
		<value>5</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>dfs.heartbeat.interval</name>
		<value>3</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>dfs.ha.fencing.ssh.connect-timeout</name>
		<value>30000</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>hbase.thrift.htablepool.size.max</name>
		<value>1000</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>hbase.regionserver.lease.period</name>
		<value>600000</value>
		<source>hbase-site.xml</source>
	</property>
	<property>
		<name>dfs.nameservices</name>
		<value>nameservice1</value>
		<source>hdfs-site.xml</source>
	</property>
	<property>
		<name>local.cache.size</name>
		<value>10737418240</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>zookeeper.znode.rootserver</name>
		<value>root-region-server</value>
		<source>hbase-site.xml</source>
	</property>
	<property>
		<name>hbase.regionserver.msginterval</name>
		<value>3000</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>io.sort.factor</name>
		<value>10</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>ha.failover-controller.graceful-fence.rpc-timeout.ms</name>
		<value>5000</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>kfs.blocksize</name>
		<value>67108864</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>mapred.task.timeout</name>
		<value>600000</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hbase.cluster.id</name>
		<value>a4807b94-6225-4532-a470-66dd1cc7eaed</value>
		<source>programatically</source>
	</property>
	<property>
		<name>hbase.rest.threads.max</name>
		<value>100</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.https-address.nameservice1.namenode143</name>
		<value>njhadoopmaster1.wind.com.cn:50470</value>
		<source>hdfs-site.xml</source>
	</property>
	<property>
		<name>hbase.master.logcleaner.plugins</name>
		<value>org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.secondary.http-address</name>
		<value>0.0.0.0:50090</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>ipc.client.idlethreshold</name>
		<value>4000</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>ipc.server.tcpnodelay</name>
		<value>false</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>ftp.bytes-per-checksum</name>
		<value>512</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.stale.datanode.interval</name>
		<value>30000</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>s3.bytes-per-checksum</name>
		<value>512</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>hbase.rpc.shortoperation.timeout</name>
		<value>10000</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>mapred.heartbeats.in.second</name>
		<value>100</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hbase.online.schema.update.enable</name>
		<value>false</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>fs.s3.block.size</name>
		<value>67108864</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>dfs.client.failover.connection.retries</name>
		<value>0</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>mapred.map.output.compression.codec</name>
		<value>org.apache.hadoop.io.compress.DefaultCodec</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hadoop.rpc.protection</name>
		<value>authentication</value>
		<source>core-site.xml</source>
	</property>
	<property>
		<name>mapred.task.cache.levels</name>
		<value>2</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>mapred.tasktracker.dns.interface</name>
		<value>default</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hadoop.security.auth_to_local</name>
		<value>DEFAULT</value>
		<source>core-site.xml</source>
	</property>
	<property>
		<name>dfs.secondary.namenode.kerberos.internal.spnego.principal</name>
		<value>${dfs.web.authentication.kerberos.principal}</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>hadoop.proxyuser.hue.hosts</name>
		<value>*</value>
		<source>core-site.xml</source>
	</property>
	<property>
		<name>ftp.client-write-packet-size</name>
		<value>65536</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>hbase.regionserver.checksum.verify</name>
		<value>false</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>fs.defaultFS</name>
		<value>hdfs://nameservice1</value>
		<source>programatically</source>
	</property>
	<property>
		<name>file.client-write-packet-size</name>
		<value>65536</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>mapred.job.reduce.memory.mb</name>
		<value>-1</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hbase.tmp.dir</name>
		<value>${java.io.tmpdir}/hbase-${user.name}</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>hbase.zookeeper.property.initLimit</name>
		<value>10</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>mapred.max.tracker.failures</name>
		<value>4</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>fs.trash.checkpoint.interval</name>
		<value>0</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>hbase.cluster.distributed</name>
		<value>true</value>
		<source>hbase-site.xml</source>
	</property>
	<property>
		<name>hadoop.http.authentication.signature.secret.file</name>
		<value>${user.home}/hadoop-http-auth-signature-secret</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>s3native.stream-buffer-size</name>
		<value>4096</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>hbase.thrift.maxWorkerThreads</name>
		<value>1000</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>mapreduce.reduce.shuffle.read.timeout</name>
		<value>180000</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>mapred.tasktracker.tasks.sleeptime-before-sigkill</name>
		<value>5000</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.checkpoint.edits.dir</name>
		<value>${dfs.namenode.checkpoint.dir}</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>fs.permissions.umask-mode</name>
		<value>022</value>
		<source>hdfs-site.xml</source>
	</property>
	<property>
		<name>mapred.max.tracker.blacklists</name>
		<value>4</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hadoop.common.configuration.version</name>
		<value>0.23.0</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>hbase.bulkload.retries.number</name>
		<value>0</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>jobclient.output.filter</name>
		<value>FAILED</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hadoop.security.group.mapping.ldap.ssl</name>
		<value>false</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>mapreduce.ifile.readahead</name>
		<value>true</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>io.serializations</name>
		<value>org.apache.hadoop.io.serializer.WritableSerialization,org.apache.hadoop.io.serializer.avro.AvroSpecificSerialization,org.apache.hadoop.io.serializer.avro.AvroReflectSerialization
		</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>fs.df.interval</name>
		<value>60000</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>hbase.rest.readonly</name>
		<value>false</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>io.seqfile.compress.blocksize</name>
		<value>1000000</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>mapred.jobtracker.taskScheduler</name>
		<value>org.apache.hadoop.mapred.JobQueueTaskScheduler</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>job.end.retry.attempts</name>
		<value>0</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>ipc.client.connect.max.retries</name>
		<value>10</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>hadoop.security.groups.cache.secs</name>
		<value>300</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>hbase.regionserver.port</name>
		<value>60020</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.delegation.key.update-interval</name>
		<value>86400000</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
		</name>
		<value>0.75f</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>mapred.tasktracker.indexcache.mb</name>
		<value>10</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hbase.regionserver.handler.count</name>
		<value>30</value>
		<source>hbase-site.xml</source>
	</property>
	<property>
		<name>hadoop.security.group.mapping.ldap.search.filter.user</name>
		<value>(&amp;(objectClass=user)(sAMAccountName={0}))</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>mapreduce.reduce.input.limit</name>
		<value>-1</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>dfs.image.compress</name>
		<value>false</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>hbase.hregion.majorcompaction</name>
		<value>86400000</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>tasktracker.http.threads</name>
		<value>40</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.kerberos.internal.spnego.principal</name>
		<value>${dfs.web.authentication.kerberos.principal}</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>fs.s3n.multipart.copy.block.size</name>
		<value>5368709120</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>fs.s3n.block.size</name>
		<value>67108864</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>mapred.job.tracker.handler.count</name>
		<value>10</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hbase.regionserver.optionalcacheflushinterval</name>
		<value>3600000</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>fs.ftp.host</name>
		<value>0.0.0.0</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>keep.failed.task.files</name>
		<value>false</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>mapred.output.compress</name>
		<value>false</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hadoop.security.group.mapping</name>
		<value>org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback
		</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>mapred.jobtracker.job.history.block.size</name>
		<value>3145728</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>mapred.skip.reduce.max.skip.groups</name>
		<value>0</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>dfs.datanode.address</name>
		<value>0.0.0.0:50010</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>dfs.datanode.https.address</name>
		<value>0.0.0.0:50475</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.servicerpc-address.nameservice1.namenode37</name>
		<value>njhadoopmaster2.wind.com.cn:8022</value>
		<source>hdfs-site.xml</source>
	</property>
	<property>
		<name>file.replication</name>
		<value>1</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>dfs.datanode.drop.cache.behind.reads</name>
		<value>false</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>hbase.regionserver.global.memstore.upperLimit</name>
		<value>0.4</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>hadoop.fuse.connection.timeout</name>
		<value>300</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>hadoop.work.around.non.threadsafe.getpwuid</name>
		<value>false</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>mapreduce.client.genericoptionsparser.used</name>
		<value>true</value>
		<source>programatically</source>
	</property>
	<property>
		<name>hadoop.tmp.dir</name>
		<value>/tmp/hadoop-${user.name}</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>dfs.client.block.write.replace-datanode-on-failure.policy</name>
		<value>DEFAULT</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>hbase.hregion.preclose.flush.size</name>
		<value>5242880</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>hbase.regionserver.global.memstore.lowerLimit</name>
		<value>0.35</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>mapred.line.input.format.linespermap</name>
		<value>1</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hadoop.kerberos.kinit.command</name>
		<value>kinit</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>dfs.webhdfs.enabled</name>
		<value>false</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.fs-limits.max-blocks-per-file</name>
		<value>1048576</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>dfs.datanode.du.reserved</name>
		<value>0</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>fs.default.name</name>
		<value>hdfs://nameservice1</value>
		<source>because fs.defaultFS is deprecated</source>
	</property>
	<property>
		<name>hbase.master.dns.interface</name>
		<value>default</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>file.bytes-per-checksum</name>
		<value>512</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>mapred.local.dir.minspacestart</name>
		<value>0</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>dfs.client.block.write.replace-datanode-on-failure.enable</name>
		<value>true</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>mapred.jobtracker.maxtasks.per.job</name>
		<value>-1</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>mapred.user.jobconf.limit</name>
		<value>5242880</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>mapred.reduce.max.attempts</name>
		<value>4</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>net.topology.script.number.args</name>
		<value>100</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.decommission.interval</name>
		<value>30</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>mapred.job.tracker</name>
		<value>local</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hbase.defaults.for.version.skip</name>
		<value>false</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>dfs.image.compression.codec</name>
		<value>org.apache.hadoop.io.compress.DefaultCodec</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.support.allow.format</name>
		<value>true</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>hadoop.ssl.hostname.verifier</name>
		<value>DEFAULT</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>ipc.client.connect.timeout</name>
		<value>20000</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>hbase.server.versionfile.writeattempts</name>
		<value>3</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>mapred.tasktracker.instrumentation</name>
		<value>org.apache.hadoop.mapred.TaskTrackerMetricsInst</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>io.mapfile.bloom.error.rate</name>
		<value>0.005</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>dfs.permissions.superusergroup</name>
		<value>supergroup</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
		</name>
		<value>10737418240</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>mapred.tasktracker.expiry.interval</name>
		<value>600000</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hadoop.proxyuser.hue.groups</name>
		<value>*</value>
		<source>core-site.xml</source>
	</property>
	<property>
		<name>hbase.master.hfilecleaner.plugins</name>
		<value>org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>hbase.regionserver.info.bindAddress</name>
		<value>0.0.0.0</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>io.sort.record.percent</name>
		<value>0.05</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>mapred.job.tracker.persist.jobstatus.active</name>
		<value>false</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>ha.failover-controller.graceful-fence.connection.retries</name>
		<value>1</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>ha.health-monitor.connect-retry-interval.ms</name>
		<value>1000</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>hbase.security.authentication</name>
		<value>simple</value>
		<source>hbase-site.xml</source>
	</property>
	<property>
		<name>dfs.namenode.checkpoint.check.period</name>
		<value>60</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>io.seqfile.local.dir</name>
		<value>${hadoop.tmp.dir}/io/local</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>tfile.io.chunk.size</name>
		<value>1048576</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>file.blocksize</name>
		<value>67108864</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>mapreduce.job.acl-modify-job</name>
		<value>
		</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>io.skip.checksum.errors</name>
		<value>false</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.edits.journal-plugin.qjournal</name>
		<value>org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>hbase.regionserver.separate.hlog.for.meta</name>
		<value>false</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>hbase.zookeeper.peerport</name>
		<value>2888</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>dfs.datanode.handler.count</name>
		<value>10</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>hbase.master.port</name>
		<value>60000</value>
		<source>hbase-site.xml</source>
	</property>
	<property>
		<name>dfs.namenode.decommission.nodes.per.interval</name>
		<value>5</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>fs.ftp.host.port</name>
		<value>21</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.checkpoint.period</name>
		<value>3600</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.fs-limits.max-component-length</name>
		<value>0</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>fs.AbstractFileSystem.viewfs.impl</name>
		<value>org.apache.hadoop.fs.viewfs.ViewFs</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>mapred.temp.dir</name>
		<value>${hadoop.tmp.dir}/mapred/temp</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hbase.client.keyvalue.maxsize</name>
		<value>10485760</value>
		<source>hbase-site.xml</source>
	</property>
	<property>
		<name>dfs.datanode.ipc.address</name>
		<value>0.0.0.0:50020</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>hadoop.ssl.require.client.cert</name>
		<value>false</value>
		<source>core-default.xml</source>
	</property>
	<property>
		<name>hbase.hregion.memstore.block.multiplier</name>
		<value>2</value>
		<source>hbase-default.xml</source>
	</property>
	<property>
		<name>dfs.namenode.servicerpc-address.nameservice1.namenode143</name>
		<value>njhadoopmaster1.wind.com.cn:8022</value>
		<source>hdfs-site.xml</source>
	</property>
	<property>
		<name>dfs.datanode.max.transfer.threads</name>
		<value>4096</value>
		<source>hdfs-default.xml</source>
	</property>
	<property>
		<name>mapred.job.reduce.input.buffer.percent</name>
		<value>0.0</value>
		<source>mapred-default.xml</source>
	</property>
	<property>
		<name>hbase.server.thread.wakefrequency</name>
		<value>10000</value>
		<source>hbase-site.xml</source>
	</property>
</configuration>